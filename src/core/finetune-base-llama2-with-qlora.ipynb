{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.31.0\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "Collecting peft==0.4.0\n",
      "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting huggingface_hub==0.17.1\n",
      "  Downloading huggingface_hub-0.17.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trl==0.4.7\n",
      "  Downloading trl-0.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting guardrail-ml==0.0.12\n",
      "  Downloading guardrail_ml-0.0.12-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting unstructured==0.7.4 (from unstructured[local-inference]==0.7.4)\n",
      "  Downloading unstructured-0.7.4-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: filelock in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (2024.7.24)\n",
      "Requirement already satisfied: requests in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (2.32.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (0.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from transformers==4.31.0) (4.66.5)\n",
      "Requirement already satisfied: psutil in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from peft==0.4.0) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from peft==0.4.0) (2.4.0)\n",
      "Collecting accelerate (from peft==0.4.0)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: fsspec in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from huggingface_hub==0.17.1) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from huggingface_hub==0.17.1) (4.12.2)\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting PyPDF2 (from guardrail-ml==0.0.12)\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting textstat (from guardrail-ml==0.0.12)\n",
      "  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: sentencepiece in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from guardrail-ml==0.0.12) (0.2.0)\n",
      "Collecting bitsandbytes (from guardrail-ml==0.0.12)\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Collecting cleantext (from guardrail-ml==0.0.12)\n",
      "  Downloading cleantext-1.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting unidecode (from guardrail-ml==0.0.12)\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pillow in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from guardrail-ml==0.0.12) (10.4.0)\n",
      "Collecting jsonformer (from guardrail-ml==0.0.12)\n",
      "  Downloading jsonformer-0.12.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: scipy in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from guardrail-ml==0.0.12) (1.14.0)\n",
      "Collecting argilla (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading argilla-2.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting chardet (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting lxml (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting msg-parser (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting nltk (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openpyxl (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pandas in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4) (2.2.2)\n",
      "Collecting pdfminer.six (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pypandoc (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting python-docx (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting python-pptx (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-magic (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting markdown (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: tabulate in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from unstructured==0.7.4->unstructured[local-inference]==0.7.4) (0.9.0)\n",
      "Collecting xlrd (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting unstructured-inference==0.5.1 (from unstructured[local-inference]==0.7.4)\n",
      "  Downloading unstructured_inference-0.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting python-multipart (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opencv-python!=4.7.0.68 (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting onnxruntime (from unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: sympy in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.4.0) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.4.0) (12.6.20)\n",
      "INFO: pip is looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting accelerate (from peft==0.4.0)\n",
      "  Downloading accelerate-0.34.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.34.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httpx>=0.26.0 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0.0,>=2.6.0 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pydantic-2.9.1-py3-none-any.whl.metadata (146 kB)\n",
      "INFO: pip is looking at multiple versions of argilla to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting argilla (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading argilla-2.0.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "  Downloading argilla-2.0.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "  Downloading argilla-1.29.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting httpx<=0.26,>=0.15 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting deprecated~=1.2.0 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting wrapt<1.15,>=1.14 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting backoff (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting monotonic (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: rich!=13.1.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (13.7.1)\n",
      "Collecting typer<0.10.0,>=0.6.0 (from argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (2024.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->trl==0.4.7)\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl==0.4.7)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->trl==0.4.7)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->trl==0.4.7)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from datasets->trl==0.4.7) (3.10.3)\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->trl==0.4.7)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fsspec (from huggingface_hub==0.17.1)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fsspec (from huggingface_hub==0.17.1)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-2.19.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec (from huggingface_hub==0.17.1)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting fsspec (from huggingface_hub==0.17.1)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is still looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets->trl==0.4.7)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting datasets (from trl==0.4.7)\n",
      "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2024.7.4)\n",
      "Collecting termcolor<3.0.0,>=2.3.0 (from jsonformer->guardrail-ml==0.0.12)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting olefile>=0.46 (from msg-parser->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: click in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (1.4.2)\n",
      "Collecting et-xmlfile (from openpyxl->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading cryptography-43.0.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyphen (from textstat->guardrail-ml==0.0.12)\n",
      "  Downloading pyphen-0.16.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: setuptools in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from textstat->guardrail-ml==0.0.12) (72.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (2.3.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.7) (4.0.3)\n",
      "Collecting anyio (from httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.6.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.3 (from pydantic<3.0.0,>=2.6.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pydantic_core-2.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from rich!=13.1.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from rich!=13.1.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (2.1.5)\n",
      "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting pdf2image (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting torchvision (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->trl==0.4.7)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting coloredlogs (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (5.27.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (2.22)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (0.1.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from anyio->httpx<=0.26,>=0.15->argilla->unstructured==0.7.4->unstructured[local-inference]==0.7.4) (1.2.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm>=0.9.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pycocotools>=2.0.2 (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (2.3.0)\n",
      "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting pdfminer.six (from unstructured==0.7.4->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Collecting torch>=1.13.0 (from peft==0.4.0)\n",
      "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.5.1->unstructured[local-inference]==0.7.4) (3.1.2)\n",
      "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
      "Downloading trl-0.4.7-py3-none-any.whl (77 kB)\n",
      "Downloading guardrail_ml-0.0.12-py3-none-any.whl (26 kB)\n",
      "Downloading unstructured-0.7.4-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_inference-0.5.1-py3-none-any.whl (39 kB)\n",
      "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
      "Downloading argilla-1.29.1-py3-none-any.whl (417 kB)\n",
      "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading cleantext-1.1.4-py3-none-any.whl (4.9 kB)\n",
      "Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading jsonformer-0.12.0-py3-none-any.whl (6.6 kB)\n",
      "Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading textstat-0.7.4-py3-none-any.whl (105 kB)\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Downloading cryptography-43.0.1-cp39-abi3-manylinux_2_28_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.1-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pyphen-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: iopath\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=e44658c98eacb8ae18940eb5417982709fa426628fac5cd1005e1236eabe6e3c\n",
      "  Stored in directory: /home/faisal/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
      "Successfully built iopath\n",
      "Installing collected packages: tokenizers, monotonic, flatbuffers, filetype, xxhash, XlsxWriter, xlrd, wrapt, unidecode, typer, termcolor, sniffio, python-multipart, python-magic, pytesseract, pyphen, pypdfium2, PyPDF2, pypandoc, pydantic-core, pyarrow-hotfix, pyarrow, portalocker, pdf2image, opencv-python, olefile, nltk, markdown, lxml, humanfriendly, h11, fsspec, et-xmlfile, dill, chardet, backoff, annotated-types, textstat, python-pptx, python-docx, pydantic, openpyxl, multiprocess, msg-parser, jsonformer, iopath, huggingface_hub, httpcore, deprecated, cryptography, coloredlogs, cleantext, anyio, transformers, torch, pycocotools, pdfminer.six, onnxruntime, httpx, torchvision, pdfplumber, datasets, bitsandbytes, argilla, accelerate, unstructured, trl, timm, peft, layoutparser, guardrail-ml, effdet, unstructured-inference\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.12.3\n",
      "    Uninstalling typer-0.12.3:\n",
      "      Successfully uninstalled typer-0.12.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.24.5\n",
      "    Uninstalling huggingface-hub-0.24.5:\n",
      "      Successfully uninstalled huggingface-hub-0.24.5\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.0\n",
      "    Uninstalling transformers-4.44.0:\n",
      "      Successfully uninstalled transformers-4.44.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyannote-database 5.1.0 requires typer>=0.12.1, but you have typer 0.9.4 which is incompatible.\n",
      "torchaudio 2.4.0 requires torch==2.4.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyPDF2-3.0.1 XlsxWriter-3.2.0 accelerate-0.32.1 annotated-types-0.7.0 anyio-4.4.0 argilla-1.29.1 backoff-2.2.1 bitsandbytes-0.43.3 chardet-5.2.0 cleantext-1.1.4 coloredlogs-15.0.1 cryptography-43.0.1 datasets-2.14.7 deprecated-1.2.14 dill-0.3.7 effdet-0.4.1 et-xmlfile-1.1.0 filetype-1.2.0 flatbuffers-24.3.25 fsspec-2023.10.0 guardrail-ml-0.0.12 h11-0.14.0 httpcore-1.0.5 httpx-0.26.0 huggingface_hub-0.17.1 humanfriendly-10.0 iopath-0.1.10 jsonformer-0.12.0 layoutparser-0.3.4 lxml-5.3.0 markdown-3.7 monotonic-1.6 msg-parser-1.2.0 multiprocess-0.70.15 nltk-3.9.1 olefile-0.47 onnxruntime-1.19.2 opencv-python-4.10.0.84 openpyxl-3.1.5 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.4 peft-0.4.0 portalocker-2.10.1 pyarrow-17.0.0 pyarrow-hotfix-0.6 pycocotools-2.0.8 pydantic-2.9.1 pydantic-core-2.23.3 pypandoc-1.13 pypdfium2-4.30.0 pyphen-0.16.0 pytesseract-0.3.13 python-docx-1.1.2 python-magic-0.4.27 python-multipart-0.0.9 python-pptx-1.0.2 sniffio-1.3.1 termcolor-2.4.0 textstat-0.7.4 timm-1.0.9 tokenizers-0.13.3 torch-2.4.1 torchvision-0.19.1 transformers-4.31.0 trl-0.4.7 typer-0.9.4 unidecode-1.3.8 unstructured-0.7.4 unstructured-inference-0.5.1 wrapt-1.14.1 xlrd-2.0.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.31.0 peft==0.4.0 huggingface_hub==0.17.1 trl==0.4.7 guardrail-ml==0.0.12 unstructured[\"local-inference\"]==0.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['LD_LIBRARY_PATH'] = 'C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v11.5\\\\lib\\\\x64'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.training_args because of the following error (look up to see its traceback):\ncannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (/home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/transformers/utils/import_utils.py:1099\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/transformers/training_args.py:67\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available():\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AcceleratorState, PartialState\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedType\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/accelerate/__init__.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.32.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     cpu_offload,\n\u001b[1;32m     19\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/accelerate/accelerator.py:34\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_torch_state_dict_into_shards\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (/home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages/huggingface_hub/__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m      6\u001b[0m     AutoTokenizer,\n\u001b[1;32m      7\u001b[0m     BitsAndBytesConfig,\n\u001b[1;32m      8\u001b[0m     HfArgumentParser,\n\u001b[1;32m      9\u001b[0m     TrainingArguments,\n\u001b[1;32m     10\u001b[0m     pipeline,\n\u001b[1;32m     11\u001b[0m     logging,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, PeftModel, get_peft_model\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/transformers/utils/import_utils.py:1089\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1089\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.10/site-packages/transformers/utils/import_utils.py:1101\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.training_args because of the following error (look up to see its traceback):\ncannot import name 'split_torch_state_dict_into_shards' from 'huggingface_hub' (/home/faisal/anaconda3/envs/dl/lib/python3.10/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from guardrail.client import (\n",
    "    run_metrics,\n",
    "    run_simple_metrics,\n",
    "    create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for multi-gpu\n",
    "local_rank = -1\n",
    "per_device_train_batch_size = 4\n",
    "per_device_eval_batch_size = 4\n",
    "gradient_accumulation_steps = 1\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "weight_decay = 0.001\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "max_seq_length = None\n",
    "\n",
    "# The model that you want to train from the Hugging Face hub\n",
    "# model_name = \"guardrail/llama-2-7b-guanaco-instruct-sharded\"\n",
    "# model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"llama-2-7b-dental-test-v1\"\n",
    "\n",
    "# The instruction dataset to use\n",
    "dataset_name = \"/kaggle/input/llama2-dental-no-context\"\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Activate nested quantization for 4-bit base models\n",
    "use_nested_quant = False\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 2\n",
    "\n",
    "# Enable fp16 training, (bf16 to True with an A100)\n",
    "fp16 = False\n",
    "\n",
    "# Enable bf16 training\n",
    "bf16 = False\n",
    "\n",
    "# Use packing dataset creating\n",
    "packing = False\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Optimizer to use, original is paged_adamw_32bit\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule (constant a bit better than cosine, and has advantage for analysis)\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of optimizer update steps, 10K original, 20 for demo purposes\n",
    "max_steps = -1\n",
    "\n",
    "# Fraction of steps to do a warmup for\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length (saves memory and speeds up training considerably)\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 10\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 1\n",
    "\n",
    "# The output directory where the model predictions and checkpoints will be written\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# Visualize training\n",
    "report_to = \"tensorboard\"\n",
    "\n",
    "# Tensorboard logs\n",
    "tb_log_dir = \"./results/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    # Load tokenizer and model with QLoRA configuration\n",
    "    compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=use_4bit,\n",
    "        bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=use_nested_quant,\n",
    "    )\n",
    "\n",
    "    if compute_dtype == torch.float16 and use_4bit:\n",
    "        major, _ = torch.cuda.get_device_capability()\n",
    "        if major >= 8:\n",
    "            print(\"=\" * 80)\n",
    "            print(\"Your GPU supports bfloat16, you can accelerate training with the argument --bf16\")\n",
    "            print(\"=\" * 80)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=device_map,\n",
    "        quantization_config=bnb_config\n",
    "    )\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "\n",
    "    # Load LoRA configuration\n",
    "    peft_config = LoraConfig(\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=lora_dropout,\n",
    "        r=lora_r,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    # Load Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "\n",
    "    return model, tokenizer, peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# !python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('7dfdc3694ead1a038bfa1cbe7bbe7946c722635d')\"\n",
    "login(token=\"YOUR HUGGING FACE TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer, peft_config = load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dolly(sample):\n",
    "#     print(\"dolly data: \", sample)\n",
    "    instruction = f\"<s>[INST] {sample['question']}\"\n",
    "#     context = f\"<<SYS>>{sample['context']}<<SYS>>\" if len(sample[\"context\"]) > 0 else None\n",
    "    response = f\" [/INST] {sample['answer']}\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\".join([i for i in [instruction, response] if i is not None])\n",
    "#     print(\"prompt data:\", prompt)\n",
    "    return prompt\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "#     print(\"updated sample: \", sample)\n",
    "    return sample\n",
    "\n",
    "# apply prompt template per sample\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset_shuffled = dataset.shuffle(seed=42)\n",
    "\n",
    "# Select the first 50 rows from the shuffled dataset, comment if you want 15k\n",
    "dataset = dataset_shuffled.select(range(100))\n",
    "print(dataset.features)\n",
    "dataset = dataset.map(template_dataset, remove_columns=list(dataset.features))\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"What potential drug interactions are associated with abacavir in dental practice?\"\n",
    "# Ignore warnings\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST]{prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "# logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"do you know what is Acebutolol?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1024)\n",
    "result = pipe(f\"<s>[INST]{prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# Empty VRAM\n",
    "del model\n",
    "del pipe\n",
    "del trainer\n",
    "import gc\n",
    "gc.collect()\n",
    "gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reload model in FP16 and merge it with LoRA weights\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     return_dict=True,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map=device_map,\n",
    "# )\n",
    "# model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "# model = model.merge_and_unload()\n",
    "\n",
    "# # Reload tokenizer to save it\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
